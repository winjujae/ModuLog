import openai
import re
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from langdetect import detect, LangDetectException
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# MBART ëª¨ë¸ ë¡œë“œ (ë‹¤êµ­ì–´ í›„ì† ë²ˆì—­ìš©)
model_name = "facebook/mbart-large-50-many-to-many-mmt"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# ì–¸ì–´ ì½”ë“œ ë§¤í•‘ (MBARTìš©)
lang_code_map_mbart = {
    "ko": "ko_KR",
    "zh": "zh_CN",
    "en": "en_XX"
}

# âœ… GPT ê¸°ë°˜ í˜¼í•©ì–¸ì–´ â†’ ë²ˆì—­

# ìµœì‹  ë²„ì „ìš© GPT í˜¸ì¶œ í•¨ìˆ˜ (openai>=1.0.0 ëŒ€ì‘)
def gpt_translate_mixed(text, target_lang="en"):
    system_prompt = "You are a professional translator that understands multilingual and code-switched sentences."
    user_prompt = f"""Please translate the following text into {target_lang.upper()}.
This text may contain Korean, Chinese, or English mixed in a single sentence.
Make sure to preserve the meaning and produce fluent, natural output.

Text:
{text}"""

    response = openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# âœ… ì˜ì–´ â†’ ë‹¤êµ­ì–´ (í•œêµ­ì–´, ì¤‘êµ­ì–´)

def translate_from_en(text, target_lang):
    assert target_lang in ["ko", "zh"], "ì§€ì› ì–¸ì–´: ko (í•œêµ­ì–´), zh (ì¤‘êµ­ì–´)"
    tgt_lang_code = lang_code_map_mbart[target_lang]
    tokenizer.src_lang = lang_code_map_mbart["en"]
    encoded = tokenizer(text, return_tensors="pt")
    output = model.generate(
        **encoded,
        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang_code]
    )
    return tokenizer.decode(output[0], skip_special_tokens=True)

# âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜

def multilingual_pipeline(text):
    # print("ğŸ“Œ ì›ë¬¸:\n", text)

    # Step 1: í˜¼í•©ì–¸ì–´ â†’ ì˜ì–´ ë²ˆì—­ (GPT)
    english_text = gpt_translate_mixed(text)

    # Step 2: ì˜ì–´ â†’ í•œêµ­ì–´/ì¤‘êµ­ì–´ ë²ˆì—­ (ìš”ì•½ ì—†ì´ ë°”ë¡œ)
    korean = translate_from_en(english_text, "ko")
    chinese = translate_from_en(english_text, "zh")

    # print("\nğŸ‡°ğŸ‡· í•œêµ­ì–´ ìš”ì•½:\n", korean)
    # print("\nğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ ìš”ì•½:\n", chinese)

    return {
        "en": english_text,
        "ko": korean,
        "zh": chinese
    }

