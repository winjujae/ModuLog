from Langchain_pipeline import RAGpipeline
from Langchain_pipeline import run_rag_pipeline
from translator05 import multilingual_pipeline
from summarize_pipeline import load_model_and_tokenizer, summarize_text
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

if __name__ == "__main__":
    # ğŸ”§ ì—¬ê¸°ì„œ ì–´ë–¤ ê¸°ëŠ¥ì„ ì‹¤í–‰í• ì§€ ì„ íƒ
    mode = input("ì‹¤í–‰í•  ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” ('chat' ë˜ëŠ” 'translate'): ").strip().lower()
    
    model_name = "google/long-t5-tglobal-base"
    weights_path = "longt5_finetuned_using4096(Ep22).pth"

    input_text = """
    **Transformers Library:** The Transformers library provides a unified interface for more than 50 pre-trained models,
    simplifying the development of NLP applications. 
    **Hugging Face Transformers Community:** Hugging Face has fostered a vibrant online community where developers, 
    researchers, and AI enthusiasts can share their knowledge, code, and insights.
    
    å¾ˆé«˜å…´è§åˆ°ä½ ã€‚ é‡‘ç»„é•¿ï¼Œä»Šå¤©æœ‰ä»€ä¹ˆäº‹è¦è§é¢å‘¢ï¼Ÿ
    ì•ˆë…•í•˜ì„¸ìš” ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ì•„ìš” ì§€ê¸ˆ ê³µì›ì— ê°€ê³  ìˆì–´ìš” ä»Šå¤©å¤©æ°”å¾ˆå¥½ æˆ‘ä»¬å»åƒé¥­å§ ë°°ê³ íŒŒ ì£½ê² ì–´
    ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ä»Šå¤© ì •ë§ ì¢‹ì•„
     """

    tokenizer, model, device = load_model_and_tokenizer(model_name, weights_path)
    summary = summarize_text(input_text, tokenizer, model, device)

    print("=== Input ===")
    print(input_text[:300] + "...")  # ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ ì¶œë ¥

    print("\n=== Summary ===")
    print(summary)
    
    # íšŒì˜ë¡ ì „ë¬¸
    # meeting_text = """
    # ë¬¸ì„œì˜ ë‚´ìš©ì€ ì˜¤ëŠ˜ íšŒì˜ì—ì„œ AI ìœ¤ë¦¬ ê¸°ì¤€ ì •ë¹„ì™€ ê´€ë ¨ëœ ì´ìŠˆê°€ ì£¼ìš”í•˜ê²Œ ë…¼ì˜ë˜ì—ˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.
    # êµ¬ì²´ì ìœ¼ë¡œëŠ” ê¸°ì—… ë‚´ë¶€ ë°ì´í„° í™œìš© ê³¼ ê°œì¸ì •ë³´ ë³´í˜¸ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ë¬¸ì œ,
    # ê·¸ë¦¬ê³  ì„¤ëª… ê°€ëŠ¥í•œ AI ì‹œìŠ¤í…œì˜ í•„ìš”ì„±ì— ëŒ€í•œ ë…¼ì˜ê°€ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.
    # """

    if mode == "chat":
        query = input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! : ")
        run_rag_pipeline(pdf_path=None, input_text= summary, query=query)  # ë˜ëŠ” PDF ê²½ë¡œ ì…ë ¥
    elif mode == "translate":
        result = multilingual_pipeline(summary)
        print("ì˜ë¬¸ : ",result['en'])
        print("í•œêµ­ì–´ : ",result['ko'])
        print("ì¤‘êµ­ì–´ : ",result['zh'])
    else:
        print("âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë“œì…ë‹ˆë‹¤. 'chat' ë˜ëŠ” 'translate' ì¤‘ ì„ íƒí•˜ì„¸ìš”.")